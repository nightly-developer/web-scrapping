{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "website = open('/home/sanchez/VS code/input files/important words.html','r')\n",
    "soup = bs(website,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = soup.find_all('li', class_ = 'entry')\n",
    "#print(word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for index,word_itr in enumerate(words):\n",
    "  if True or index <= limit:\n",
    "    word = word_itr.a.text.strip() # word to learn\n",
    "    #print(word)\n",
    "    vocabulary[word] = {}\n",
    "    #vocabulary['word'] = word\n",
    "    vocabulary[word]['meaning'] = word_itr.a['title'] # meaning of word\n",
    "    #print(meaning)\n",
    "    #vocabulary['meaning'] = meaning\n",
    "    details = bs(requests.get(word_itr.a['href']).text,'lxml') # link for more datails of word\n",
    "    vocabulary[word]['breif'] = details.find('p',class_ = 'short').text # breif info of word\n",
    "    #print(breif) #----> part of vocabulary\n",
    "    definations = details.find_all('li',class_ = 'sense')\n",
    "    vocabulary[word]['POS'] = {}\n",
    "    vocabulary[word]['example'] = []\n",
    "    for defination in definations:\n",
    "      div = (defination.find('div',class_ = 'definition'))\n",
    "      pos_meaning = (re.sub('\\n|\\t|\\r','',div.text)).split(' ',1)\n",
    "      pos = pos_meaning[0] # part of speech \n",
    "      if pos not in vocabulary[word]['POS']:\n",
    "        vocabulary[word]['POS'][pos] = []        \n",
    "      meaning = pos_meaning[1].strip() # meanig of word\n",
    "      #print(pos,\"\\t\",meaning)\n",
    "      vocabulary[word]['POS'][pos].append(meaning)\n",
    "      if defination.find('div',class_ = 'example'):\n",
    "        vocabulary[word]['example'].append(re.sub('\\n|\\r|\\t|“|”','',defination.find('div',class_ = 'example').text))\n",
    "        #print(\"Ex.\",re.sub('\\n|\\r|\\t|“|”','',defination.find('div',class_ = 'example').text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################### saving vocabulary in JSON File #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writng vocabulary in json file\n",
    "json_obj = json.dumps(vocabulary, indent=4)\n",
    "with open('vocabulary.json', 'w') as outfile:\n",
    "  outfile.write(json_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################# JSON ----> CSV ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(vocabulary, indent=4)\n",
    "with open('vocabulary.json', 'w') as outfile:\n",
    "  outfile.write(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.json','r') as json_in_file:\n",
    "  data = json.load(json_in_file)\n",
    "#creating writing file\n",
    "data_file = open('vocabulary.csv','w') \n",
    "#creating writer for writing file\n",
    "csv_writer = csv.writer(data_file)\n",
    "header = ['sr no','word', 'meaning', 'breif', 'verb', 'noun', 'adjective', 'determiner', 'adverb', 'pronoun', 'perposition', 'conjunction', 'interjection']\n",
    "sr_no = 0\n",
    "line = True\n",
    "for writer in data:\n",
    "  if line == True:\n",
    "    csv_writer.writerow(list(map(lambda x:x.upper(),header)))\n",
    "    line = False\n",
    "  row = [None] * (len(header)+1)\n",
    "  row[1] = writer\n",
    "  row[2] = data[writer]['meaning']\n",
    "  row[3] = data[writer]['breif']\n",
    "  for index in range(4):\n",
    "    for something in (data[writer]['POS']):\n",
    "      if len(data[writer]['POS'][something]) > index:\n",
    "        column = header.index(something)\n",
    "        row[column] = data[writer]['POS'][something][index-1]\n",
    "    if len(data[writer]['POS'][something]) > index:\n",
    "      if row[1] != None:\n",
    "        sr_no  += 1\n",
    "        row[0] = sr_no\n",
    "      csv_writer.writerow(row)\n",
    "      row[0] = row[1] =  row[2] = row[3] = row[column] =None\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################## CODE testing ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"section examples\">\n",
      "<vcom:examples count=\"4\" word=\"fiasco\"></vcom:examples>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(details.find('div',class_ = 'section examples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['sr. no','word', 'meaning', 'breif', 'verb', 'noun', 'adjective', 'determiner', 'adverb', 'pronoun', 'perposition', 'conjunction', 'interjection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_obj = json.dumps(vocabulary, indent=4)\n",
    "with open('vocabulary.json', 'w') as outfile:\n",
    "  outfile.write(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.json','r') as json_in_file:\n",
    "  data = json.load(json_in_file)\n",
    "#creating writing file\n",
    "data_file = open('vocabulary.csv','w') \n",
    "#creating writer for writing file\n",
    "csv_writer = csv.writer(data_file)\n",
    "header = ['sr no','word', 'meaning', 'breif', 'verb', 'noun', 'adjective', 'determiner', 'adverb', 'pronoun', 'perposition', 'conjunction', 'interjection']\n",
    "sr_no = 0\n",
    "line = True\n",
    "for writer in data:\n",
    "  if line == True:\n",
    "    csv_writer.writerow(list(map(lambda x:x.upper(),header)))\n",
    "    line = False\n",
    "  row = [None] * (len(header)+1)\n",
    "  row[1] = writer\n",
    "  row[2] = data[writer]['meaning']\n",
    "  row[3] = data[writer]['breif']\n",
    "  for index in (range(4)):\n",
    "    for something in (data[writer]['POS']):\n",
    "      if len(data[writer]['POS'][something]) > index:\n",
    "        column = header.index(something)\n",
    "        row[column] = data[writer]['POS'][something][index-1]\n",
    "    if len(data[writer]['POS'][something]) > index:\n",
    "      if row[1] != None:\n",
    "        sr_no  += 1\n",
    "        row[0] = sr_no\n",
    "      csv_writer.writerow(row)\n",
    "      row[0] = row[1] =  row[2] = row[3] = row[column] =None\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a complete failure or collapse\n"
     ]
    }
   ],
   "source": [
    "for index in range(4):\n",
    "  for something in vocabulary[writer]['POS']:\n",
    "    if len(vocabulary[writer]['POS'][something]) > index:\n",
    "      print(vocabulary[writer]['POS'][something][index-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [None] * len(header)\n",
    "row[0] = writer\n",
    "row[1] = vocabulary[writer]['meaning']\n",
    "row[2] = vocabulary[writer]['breif']\n",
    "#[row.append(col) for col in vocabulary[writer].values()]\n",
    "for something in vocabulary[writer]['POS']:\n",
    "  for index in range(len(vocabulary[writer]['POS'][something])):\n",
    "    row[header.index(something)] = vocabulary[writer]['POS'][something][index]\n",
    "    print(row)\n",
    "    break\n",
    "#row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vocab in vocabulary:\n",
    "  print(vocab)\n",
    "  print(vocabulary[vocab]['meaning'])\n",
    "  print(vocabulary[vocab]['breif'])\n",
    "  print(vocabulary[vocab]['POS'])\n",
    "  print(vocabulary[vocab]['example'])\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocabulary = {}\n",
    "vocabulary[word1] = {\n",
    "    'meaning' = meaning,\n",
    "    'breif' = breif,\n",
    "    'pos' = {\n",
    "      'pos1' = [ex1, ex2, ...],\n",
    "      'pos2' = [ex1, ex2, ...],\n",
    "      ...\n",
    "    }\n",
    "    'usage' = [setense1, setense2, ...]\n",
    "  }\n",
    "vocabulary[word2] = {\n",
    "  ....\n",
    "}\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sense = details.find_all('li',class_ = 'sense')\n",
    "for something in sense:\n",
    "  div = (something.find('div',class_ = 'definition'))\n",
    "  pos_meaning = (re.sub('\\n|\\t|\\r','',div.text)).split(' ',1)\n",
    "  pos = pos_meaning[0]\n",
    "  meaning = pos_meaning[1].replace(' ','')\n",
    "  print(pos,\"\\t\",meaning)\n",
    "  if something.find('div',class_ = 'example'):\n",
    "    print(\"Ex.\",re.sub('\\n|\\r|\\t|“|”','',something.find('div',class_ = 'example').text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################BACK UP CODE#########################\n",
    "for definitions in (details.find('div', class_ = 'word-definitions')).find_all('li'):\n",
    "      for index,definition in enumerate(definitions.find_all('div',class_ = lambda x: x in['definition' ,'example'])):\n",
    "        # if (definition.div):\n",
    "        if definition['class'][0] == 'definition':\n",
    "          vocabulary['definition '+str(index+1)] = definition.text.replace('\\t','').replace('\\r','')\n",
    "          print(definition.text.replace('\\t','').replace('\\r','')+\" this is definition\")\n",
    "          if definition['class'][0] == 'example':\n",
    "            vocabulary['Example'+str(index+1)] = definition.text.replace('\\n','').replace('\\r','')\n",
    "            print(\"Ex.\",definition.text.replace('\\n','').replace('\\r','')+\" this is example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#figure out len od POS\n",
    "vocabulary['word'] = {}\n",
    "vocabulary['word']['meaning'] = 'meaning'\n",
    "vocabulary['word']['breif'] = 'breif'\n",
    "vocabulary['word']['POS'] = list(vocabulary[word_list[pos_list.index(max(pos_list))]]['POS'].keys())\n",
    "#compare pos of word with counm head and then put that example in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#findout which word has max pos then create colunm for those pos\n",
    "pos_list = []\n",
    "for pos_itr in vocabulary:\n",
    "  pos_list.append(len(vocabulary[pos_itr]['POS'].keys()))\n",
    "\n",
    "list(vocabulary[word_list[pos_list.index(max(pos_list))]]['POS'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['WORD','MEANING','BREIF']\n",
    "header_pos = []\n",
    "[header_pos.append(element) for element in list(vocabulary[word_list[pos_list.index(max(pos_list))]]['POS'].keys())]\n",
    "list(map(lambda x:header.append(x.upper()),header_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(4):\n",
    "  for sr_no,something in enumerate(vocabulary[writer]['POS']):\n",
    "    print(vocabulary[writer])\n",
    "    \n",
    "    for index in range(len(vocabulary[writer]['POS'][something])):\n",
    "      print(index)\n",
    "      #print(sr_no+1,something,len(vocabulary[writer]['POS'][something]))\n",
    "      \n",
    "      column = header.index(something)\n",
    "      row[column] = vocabulary[writer]['POS'][something][index-1]\n",
    "      index += 1\n",
    "      row[0] = line_index  \n",
    "      csv_writer.writerow(row)\n",
    "      row[1] = row[2] = row[3] = None\n",
    "      line_index += 1\n",
    "      \n",
    "  for something in vocabulary[writer]['POS']:\n",
    "    for index in range(len(vocabulary[writer]['POS'][something])):\n",
    "      row[0] = line_index\n",
    "      column = header.index(something)\n",
    "      row[column] = vocabulary[writer]['POS'][something][index]\n",
    "      #csv_writer.writerow(row)\n",
    "      print(row)\n",
    "      row[1] = row[2] = row[3] = row[column] = None\n",
    "      line_index += 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
